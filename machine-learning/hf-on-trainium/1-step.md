# HuggingFace ðŸ¤— on AWS Tranium

In this workshop, we will demonstrate how to accelerate [ðŸ¤— Transformers](https://huggingface.co/docs/transformers/index) training by using [AWS Trainium](https://aws.amazon.com/machine-learning/trainium/), a 2nd generation ML chip optimized for training state-of-the-art models.

Using the [AWS Neuron SDK](https://aws.amazon.com/machine-learning/neuron/), we will show how anyone can start using AWS Trainium by changing just a few lines of code.

![HF on Trainium](hf_on_trainium.png)

[![go to lab](../../_media/go-to-lab.png)](https://github.com/JGalego/hf-on-trainium)
